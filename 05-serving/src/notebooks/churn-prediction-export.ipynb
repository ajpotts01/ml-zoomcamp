{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard lib\n",
    "import pickle\n",
    "from typing import Union, Tuple\n",
    "\n",
    "# Non-standard lib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../../data/telco.csv\"\n",
    "OUTPUT_PATH = \"../models/model_reg=%s.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn = pd.read_csv(DATA_PATH)\n",
    "\n",
    "numeric_variables = ['tenure', 'monthlycharges', 'totalcharges']\n",
    "categorical_variables = ['gender', 'seniorcitizen', 'partner', 'dependents',\n",
    "       'phoneservice', 'multiplelines', 'internetservice',\n",
    "       'onlinesecurity', 'onlinebackup', 'deviceprotection', 'techsupport',\n",
    "       'streamingtv', 'streamingmovies', 'contract', 'paperlessbilling',\n",
    "       'paymentmethod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_transformations(\n",
    "    target: Union[pd.core.strings.accessor.StringMethods, pd.core.indexes.base.Index]\n",
    ") -> Union[pd.core.series.Series, pd.core.indexes.base.Index]:\n",
    "    \"\"\"\n",
    "        Stage 1 cleaning for this churn prediction:\n",
    "        - Lower case for everything\n",
    "        - Spaces replaced by underscores\n",
    "\n",
    "        Can work on either Pandas indices (e.g. column headers) or Pandas series (e.g. row data)\n",
    "        \n",
    "        :param StringMethods | Index target: the target row or column to standardise\n",
    "        :return StringMethods | Index result: the standardised row or column\n",
    "\n",
    "        Note the return types are using typing since this was written pre-3.10.\n",
    "    \"\"\"\n",
    "    result = (\n",
    "        target\n",
    "        .str\n",
    "        .lower()\n",
    "        .str\n",
    "        .replace(' ', '_')\n",
    "    )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix lack of consistency in columns\n",
    "def standardise_strings(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_new = df.copy()\n",
    "    df_new.columns = string_transformations(target=df_new.columns)\n",
    "\n",
    "    object_filter = df_new.dtypes == type(object)\n",
    "\n",
    "    categorical_columns = list(df_new.dtypes[object_filter].index)\n",
    "    df_new[categorical_columns] = df_new[categorical_columns].apply(func=string_transformations, axis=1)\n",
    "    return df_new\n",
    "\n",
    "def standardise_float(df: pd.DataFrame, col_name: str) -> pd.DataFrame:\n",
    "    new_col = pd.to_numeric(df[col_name], errors='coerce')\n",
    "\n",
    "    df_new = df.copy()\n",
    "    df_new[col_name] = new_col.fillna(0)\n",
    "\n",
    "    return df_new\n",
    "\n",
    "def encode_labels(df: pd.DataFrame, col_name: str, encode_value: str) -> pd.DataFrame:\n",
    "    new_col = (df[col_name] == encode_value).astype(int)\n",
    "\n",
    "    df_new = df.copy()\n",
    "    df_new[col_name] = new_col\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_churn_standardised = standardise_strings(df_churn)\n",
    "df_fixed_charges = standardise_float(df=df_churn_standardised, col_name='totalcharges')\n",
    "df_encoded_labels = encode_labels(df=df_fixed_charges, col_name='churn', encode_value='yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df_encoded_labels, test_size=0.2, random_state=1)\n",
    "y_test = df_test['churn'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(df: pd.DataFrame, y_train: np.ndarray, categorical: list[str], numerical: list[str], regularization_factor: float = 1.0) -> Tuple[DictVectorizer, LogisticRegression]:\n",
    "    dict_train: dict = df[categorical + numerical].to_dict(orient=\"records\")\n",
    "\n",
    "    vect = DictVectorizer(sparse=False)\n",
    "    X_train = vect.fit_transform(dict_train)\n",
    "\n",
    "    model = LogisticRegression(C=regularization_factor, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return vect, model\n",
    "\n",
    "def predict(df: pd.DataFrame, vect: DictVectorizer, model: LogisticRegression, categorical: list[str], numerical: list[str]) -> np.ndarray:\n",
    "    dict_predict: dict = df[categorical + numerical].to_dict(orient=\"records\")\n",
    "\n",
    "    X = vect.transform(dict_predict)\n",
    "\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters decided from the followalong video - oddly, the follow-along differed to Alexey\n",
    "# The winning reg factor was 0.1. But then porting the code to this notebook and following along again, 1 is the winner.\n",
    "# Must have mixed up something in the variables in the (very very long) previous notebook.\n",
    "regularization_factor = 1\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(df: pd.DataFrame, categorical: list[str], numerical: list[str], train_idx: np.ndarray, val_idx: np.ndarray, regularization_factor: float) -> np.ndarray[float]:\n",
    "    df_train_next = df.iloc[train_idx]\n",
    "    df_val_next = df.iloc[val_idx]\n",
    "\n",
    "    y_train_next = df_train_next['churn'].values\n",
    "    y_val_next = df_val_next['churn'].values\n",
    "\n",
    "    vect_next, mdl_next = train(df=df_train_next, y_train=y_train_next, categorical=categorical, numerical=numerical, regularization_factor=regularization_factor)\n",
    "    y_pred_next = predict(df=df_val_next, vect=vect_next, model=mdl_next, categorical=categorical, numerical=numerical)\n",
    "\n",
    "    auc = roc_auc_score(y_val_next, y_pred_next)\n",
    "\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reg=1 0.841 +- 0.008\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "scores = []\n",
    "\n",
    "scores = [training_loop(df=df_full_train, \n",
    "                        categorical=categorical_variables, \n",
    "                        numerical=numeric_variables, \n",
    "                        train_idx=train_idx, \n",
    "                        val_idx=val_idx, \n",
    "                        regularization_factor=regularization_factor)\n",
    "        for train_idx, val_idx in k_fold.split(df_full_train)]\n",
    "\n",
    "print('Reg=%s %.3f +- %.3f' % (regularization_factor, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8587282112949182"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ah... when evaluating model earlier, must have been using wrong dataframes.\n",
    "# The AUC is clearly higher when using regularization factor of 0.1, so sticking with that.\n",
    "final_reg_factor = 0.1\n",
    "vect_final, mdl_final = train(df=df_full_train, y_train=df_full_train['churn'].values, categorical=categorical_variables, numerical=numeric_variables, regularization_factor=final_reg_factor)\n",
    "y_pred_final = predict(df=df_test, vect=vect_final, model=mdl_final, categorical=categorical_variables, numerical=numeric_variables)\n",
    "\n",
    "auc = roc_auc_score(y_test, y_pred_final)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to save!\n",
    "# Use pickle from std lib\n",
    "with open(OUTPUT_PATH % final_reg_factor, \"wb\") as file_model_output: # wb is write, binary\n",
    "    pickle.dump((vect_final, mdl_final), file_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to load!\n",
    "# Note: This requires scikit-learn to be installed\n",
    "with open(OUTPUT_PATH % \"0.1\", \"rb\") as file_model_input:\n",
    "    (loaded_vect, loaded_model) = pickle.load(file_model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_customer = dict(\n",
    "    gender=\"female\",\n",
    "    seniorcitizen=0,\n",
    "    partner=\"yes\",\n",
    "    dependents=\"no\",\n",
    "    phoneservice=\"no\",\n",
    "    multiplelines=\"no_phone_service\",\n",
    "    internetservice=\"dsl\",\n",
    "    onlinesecurity=\"no\",\n",
    "    onlinebackup=\"yes\",\n",
    "    deviceprotection=\"no\",\n",
    "    techsupport=\"no\",\n",
    "    streamingtv=\"no\",\n",
    "    streamingmovies=\"no\",\n",
    "    contract=\"month-to-month\",\n",
    "    paperlessbilling=\"yes\",\n",
    "    paymentmethod=\"electronic_check\",\n",
    "    tenure=\"1\",\n",
    "    monthlycharges=29.85,\n",
    "    totalcharges=29.85\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loaded_vect.transform([test_customer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6621058398297619"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_proba(X)[0, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (tags/v3.9.13:6de2ca5, May 17 2022, 16:36:42) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7eee6af7cac87e68df4dd0d1c115f37fc0318a2425ce5e8e24ae6dbbc2650562"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
